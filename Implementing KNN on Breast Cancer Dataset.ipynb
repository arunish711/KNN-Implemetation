{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_ds=datasets.load_breast_cancer() ## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(cancer_ds.data,cancer_ds.target) ## Splitting the dataset into\n",
    "                                                                                                ## training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=preprocessing.StandardScaler() ## Loading it to do feature scaling which is a must before working with KNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we are doing feature scaling .Note:-We are fitting the testing data on the same parameters as we have done for training\n",
    "## data.\n",
    "\n",
    "scaler.fit(x_train) \n",
    "x_train=scaler.transform(x_train) \n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function is finding the best value of no_of_neighbours with the help of cross_val_score.\n",
    "\n",
    "def fit(x_train,y_train):\n",
    "    first_run=True\n",
    "    no_of_neighbour=0\n",
    "    max_val=0.0\n",
    "    \n",
    "    for i in range(1,50,1):\n",
    "        k=0.0\n",
    "        clf=KNeighborsClassifier(n_neighbors=i)\n",
    "        score=cross_val_score(clf,x_train,y_train, cv=KFold(3,True,0))\n",
    "        \n",
    "        for j in range(len(score)):\n",
    "            k=k+score[j]\n",
    "            \n",
    "        k=k/(len(score))\n",
    "        if(max_val<k):\n",
    "            max_val=k\n",
    "            no_of_neighbours=i\n",
    "        \n",
    "    return no_of_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we are predicting the class of the individual data point of the testing data.\n",
    "\n",
    "def predict_one(x_train,y_train,x_test,k):\n",
    "    distances=[]\n",
    "    for i in range(len(x_train)):\n",
    "        distance=((x_train[i,:]-x_test)**2).sum()\n",
    "        distances.append([distance,i])\n",
    "    distances=sorted(distances)\n",
    "    \n",
    "    targets=[]\n",
    "    \n",
    "    for i in range(k):\n",
    "        index_of_training_data=distances[i][1]\n",
    "        targets.append(y_train[index_of_training_data])\n",
    "        \n",
    "        return Counter(targets).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we are finding the predictions of each and every data point and storing it in the list(predictions).\n",
    "\n",
    "def predict(x_train,y_train,x_test_data,k):\n",
    "    predictions=[]\n",
    "    for x_test in x_test_data:\n",
    "        predictions.append(predict_one(x_train,y_train,x_test,k))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=fit(x_train,y_train)## Fit function is used to find the best value of no_of_neighbours that we have to use in KNN for\n",
    "                      ## predictions.\n",
    "\n",
    "y_predict=predict(x_train,y_train,x_test,k) ## Here we are getting the predictions ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951048951048951"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_predict) ## We are getting to know about our accuracy of our predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
